{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformation with Amazon SageMaker processing job and Feature Store\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lab you will start with the raw [Women's Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) dataset and prepare it to train a BERT-based natural language processing (NLP) model. The model will be used to classify customer reviews into positive (1), neutral (0) and negative (-1) sentiment.\n",
    "\n",
    "You will convert the original review text into machine-readable features used by BERT. To perform the required feature transformation you will configure an Amazon SageMaker processing job, which will be running a custom Python script.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [1. Configure the SageMaker Feature Store](#c2w1-1.)\n",
    "  - [1.1. Configure dataset](#c2w1-1.1.)\n",
    "  - [1.2. Configure the SageMaker feature store](#c2w1-1.2.)\n",
    "    - [Exercise 1](#c2w1-ex-1)\n",
    "- [2. Transform the dataset](#c2w1-2.)\n",
    "    - [Exercise 2](#c2w1-ex-2)\n",
    "    - [Exercise 3](#c2w1-ex-3)\n",
    "- [3. Query the Feature Store](#c2w1-3.)\n",
    "  - [3.1. Export training, validation, and test datasets from the Feature Store](#c2w1-3.1.)\n",
    "    - [Exercise 4](#c2w1-ex-4)\n",
    "  - [3.2. Export TSV from Feature Store](#c2w1-3.2.)\n",
    "  - [3.3. Check that the dataset in the Feature Store is balanced by sentiment](#c2w1-3.3.)\n",
    "    - [Exercise 5](#c2w1-ex-5)\n",
    "    - [Exercise 6](#c2w1-ex-6)\n",
    "    - [Exercise 7](#c2w1-ex-7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c2/w1')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "featurestore_runtime = boto3.client(service_name='sagemaker-featurestore-runtime', \n",
    "                                    config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm,\n",
    "                         sagemaker_featurestore_runtime_client=featurestore_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-1.'></a>\n",
    "# 1. Configure the SageMaker Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-1.1.'></a>\n",
    "### 1.1. Configure dataset\n",
    "The raw dataset is in the public S3 bucket. Let's start by specifying the S3 location of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://dlai-practical-data-science/data/raw/\n"
     ]
    }
   ],
   "source": [
    "raw_input_data_s3_uri = 's3://dlai-practical-data-science/data/raw/'\n",
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the files in the S3 bucket (in this case it will be just one file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-1.2.'></a>\n",
    "### 1.2. Configure the SageMaker feature store\n",
    "\n",
    "As the result of the transformation, in addition to generating files in S3 bucket, you will also save the transformed data in the **Amazon SageMaker Feature Store** to be used by others in your organization, for example. \n",
    "\n",
    "To configure a Feature Store you need to setup a **Feature Group**. This is the main resource containing all of the metadata related to the data stored in the Feature Store. A Feature Group should contain a list of **Feature Definitions**. A Feature Definition consists of a name and the data type. The Feature Group also contains an online store configuration and an offline store configuration controlling where the data is stored. Enabling the online store allows quick access to the latest value for a record via the [GetRecord API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_feature_store_GetRecord.html). The offline store allows storage of the data in your S3 bucket. You will be using the offline store in this lab.\n",
    "\n",
    "Let's setup the Feature Group name and the Feature Store offline prefix in S3 bucket (you will use those later in the lab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group name: reviews-feature-group-1627433581\n",
      "Feature store offline prefix in S3: reviews-feature-store-1627433581\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "feature_group_name = 'reviews-feature-group-' + str(timestamp)\n",
    "feature_store_offline_prefix = 'reviews-feature-store-' + str(timestamp)\n",
    "\n",
    "print('Feature group name: {}'.format(feature_group_name))\n",
    "print('Feature store offline prefix in S3: {}'.format(feature_store_offline_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking two features from the original raw dataset (`Review Text` and `Rating`), you will transform it preparing to be used for the model training and then to be saved in the Feature Store. Here you will define the related features to be stored as a list of `FeatureDefinition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_definition import (\n",
    "    FeatureDefinition,\n",
    "    FeatureTypeEnum,\n",
    ")\n",
    "\n",
    "feature_definitions= [\n",
    "    # unique ID of the review\n",
    "    FeatureDefinition(feature_name='review_id', feature_type=FeatureTypeEnum.STRING), \n",
    "    # ingestion timestamp\n",
    "    FeatureDefinition(feature_name='date', feature_type=FeatureTypeEnum.STRING),\n",
    "    # sentiment: -1 (negative), 0 (neutral) or 1 (positive). It will be found the Rating values (1, 2, 3, 4, 5)\n",
    "    FeatureDefinition(feature_name='sentiment', feature_type=FeatureTypeEnum.STRING), \n",
    "    # label ID of the target class (sentiment)\n",
    "    FeatureDefinition(feature_name='label_id', feature_type=FeatureTypeEnum.STRING),\n",
    "    # reviews encoded with the BERT tokenizer\n",
    "    FeatureDefinition(feature_name='input_ids', feature_type=FeatureTypeEnum.STRING),\n",
    "    # original Review Text\n",
    "    FeatureDefinition(feature_name='review_body', feature_type=FeatureTypeEnum.STRING),\n",
    "    # train/validation/test label\n",
    "    FeatureDefinition(feature_name='split_type', feature_type=FeatureTypeEnum.STRING)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-1'></a>\n",
    "### Exercise 1\n",
    "\n",
    "Create the feature group using the feature definitions defined above.\n",
    "\n",
    "**Instructions:** Use the `FeatureGroup` function passing the defined above feature group name and the feature definitions.\n",
    "\n",
    "```python\n",
    "feature_group = FeatureGroup(\n",
    "    name=..., # Feature Group name\n",
    "    feature_definitions=..., # a list of Feature Definitions\n",
    "    sagemaker_session=sess # SageMaker session\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureGroup(name='reviews-feature-group-1627433581', sagemaker_session=<sagemaker.session.Session object at 0x7f72462b1a90>, feature_definitions=[FeatureDefinition(feature_name='review_id', feature_type=<FeatureTypeEnum.STRING: 'String'>), FeatureDefinition(feature_name='date', feature_type=<FeatureTypeEnum.STRING: 'String'>), FeatureDefinition(feature_name='sentiment', feature_type=<FeatureTypeEnum.STRING: 'String'>), FeatureDefinition(feature_name='label_id', feature_type=<FeatureTypeEnum.STRING: 'String'>), FeatureDefinition(feature_name='input_ids', feature_type=<FeatureTypeEnum.STRING: 'String'>), FeatureDefinition(feature_name='review_body', feature_type=<FeatureTypeEnum.STRING: 'String'>), FeatureDefinition(feature_name='split_type', feature_type=<FeatureTypeEnum.STRING: 'String'>)])\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    name=feature_group_name, # Replace None\n",
    "    feature_definitions=feature_definitions, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "print(feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the defined Feature Group later in this lab, the actual creation of the Feature Group will take place in the processing job. Now let's move into the setup of the processing job to transform the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-2.'></a>\n",
    "# 2. Transform the dataset\n",
    "\n",
    "You will configure a SageMaker processing job to run a custom Python script to balance and transform the raw data into a format used by BERT model.\n",
    "\n",
    "Set the transformation parameters including the instance type, instance count, and train/validation/test split percentages. For the purposes of this lab, you will use a relatively small instance type. Please refer to [this](https://aws.amazon.com/sagemaker/pricing/) link for additional instance types that may work for your use case outside of this lab.\n",
    "\n",
    "You can also choose whether you want to balance the dataset or not. In this case, you will balance the dataset to avoid class imbalance in the target variable, `sentiment`. \n",
    "\n",
    "Another important parameter of the model is the `max_seq_length`, which specifies the maximum length of the classified reviews for the RoBERTa model. If the sentence is shorter than the maximum length parameter, it will be padded. In another case, when the sentence is longer, it will be truncated from the right side.\n",
    "\n",
    "Since a smaller `max_seq_length` leads to faster training and lower resource utilization, you want to find the smallest power-of-2 that captures `100%` of our reviews.  For this dataset, the `100th` percentile is `115`.  However, it's best to stick with powers-of-2 when using BERT. So let's choose `128` as this is the smallest power-of-2 greater than `115`. You will see below how the shorter sentences will be padded to a maximum length.\n",
    "\n",
    "\n",
    "```\n",
    "mean        52.512374\n",
    "std         31.387048\n",
    "min          1.000000\n",
    "10%         10.000000\n",
    "20%         22.000000\n",
    "30%         32.000000\n",
    "40%         41.000000\n",
    "50%         51.000000\n",
    "60%         61.000000\n",
    "70%         73.000000\n",
    "80%         88.000000\n",
    "90%         97.000000\n",
    "100%       115.000000\n",
    "max        115.000000\n",
    "```\n",
    "\n",
    "![](images/distribution_num_words_per_review.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processing_instance_type='ml.c5.xlarge'\n",
    "processing_instance_count=1\n",
    "train_split_percentage=0.90\n",
    "validation_split_percentage=0.05\n",
    "test_split_percentage=0.05\n",
    "balance_dataset=True\n",
    "max_seq_length=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To balance and transform our data, you will use a scikit-learn-based processing job. This is essentially a generic Python processing job with scikit-learn pre-installed. You can specify the version of scikit-learn you wish to use. Also pass the SageMaker execution role, processing instance type and instance count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={'AWS_DEFAULT_REGION': region},                             \n",
    "    max_runtime_in_seconds=7200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing job will be running the Python code from the file `src/prepare_data.py`. In the following exercise you will review the contents of the file and familiarize yourself with main parts of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-2'></a>\n",
    "### Exercise 2\n",
    "\n",
    "1. Open the file [src/prepare_data.py](src/prepare_data.py). Go through the comments to understand its content.\n",
    "2. Find and review the `convert_to_bert_input_ids()` function, which contains the RoBERTa `tokenizer` configuration.\n",
    "3. Complete method `encode_plus` of the RoBERTa `tokenizer`. Pass the `max_seq_length` as a value for the argument `max_length`. It defines a pad to a maximum length specified.\n",
    "4. Save the file [src/prepare_data.py](src/prepare_data.py) (with the menu command File -> Save Python File)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _This cell will take approximately 1-2 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ed676e2ebf4ccba4c01fcf81f237da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85510242ff54782b46124555a0625fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################\n",
      "Updated correctly!\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "sys.path.append('src/')\n",
    "\n",
    "# import the `prepare_data.py` module\n",
    "import prepare_data\n",
    "\n",
    "# reload the module if it has been previously loaded \n",
    "if 'prepare_data' in sys.modules:\n",
    "    importlib.reload(prepare_data)\n",
    "\n",
    "input_ids = prepare_data.convert_to_bert_input_ids(\"this product is great!\", max_seq_length)\n",
    "    \n",
    "updated_correctly = False\n",
    "\n",
    "if len(input_ids) != max_seq_length:\n",
    "    print('#######################################################################################################')\n",
    "    print('Please check that the function \\'convert_to_bert_input_ids\\' in the file src/prepare_data.py is complete.')\n",
    "    print('#######################################################################################################')\n",
    "    raise Exception('Please check that the function \\'convert_to_bert_input_ids\\' in the file src/prepare_data.py is complete.')\n",
    "else:\n",
    "    print('##################')\n",
    "    print('Updated correctly!')\n",
    "    print('##################')\n",
    "\n",
    "    updated_correctly = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the results of tokenization for the given example (*\\\"this product is great!\\\"*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9226, 1152, 16, 372, 328, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length of the sequence: 128\n"
     ]
    }
   ],
   "source": [
    "input_ids = prepare_data.convert_to_bert_input_ids(\"this product is great!\", max_seq_length)\n",
    "\n",
    "print(input_ids)\n",
    "print('Length of the sequence: {}'.format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the processing job with the custom script passing defined above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2021-07-28-00-58-27-975\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://dlai-practical-data-science/data/raw/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/input/code/prepare_data.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'sentiment-train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-train', 'LocalPath': '/opt/ml/processing/output/sentiment/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'sentiment-validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-validation', 'LocalPath': '/opt/ml/processing/output/sentiment/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'sentiment-test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-test', 'LocalPath': '/opt/ml/processing/output/sentiment/test', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "if (updated_correctly):\n",
    "\n",
    "    processor.run(code='src/prepare_data.py',\n",
    "              inputs=[\n",
    "                    ProcessingInput(source=raw_input_data_s3_uri,\n",
    "                                    destination='/opt/ml/processing/input/data/',\n",
    "                                    s3_data_distribution_type='ShardedByS3Key')\n",
    "              ],\n",
    "              outputs=[\n",
    "                    ProcessingOutput(output_name='sentiment-train',\n",
    "                                     source='/opt/ml/processing/output/sentiment/train',\n",
    "                                     s3_upload_mode='EndOfJob'),\n",
    "                    ProcessingOutput(output_name='sentiment-validation',\n",
    "                                     source='/opt/ml/processing/output/sentiment/validation',\n",
    "                                     s3_upload_mode='EndOfJob'),\n",
    "                    ProcessingOutput(output_name='sentiment-test',\n",
    "                                     source='/opt/ml/processing/output/sentiment/test',\n",
    "                                     s3_upload_mode='EndOfJob')\n",
    "              ],\n",
    "              arguments=['--train-split-percentage', str(train_split_percentage),\n",
    "                         '--validation-split-percentage', str(validation_split_percentage),\n",
    "                         '--test-split-percentage', str(test_split_percentage),\n",
    "                         '--balance-dataset', str(balance_dataset),\n",
    "                         '--max-seq-length', str(max_seq_length),                         \n",
    "                         '--feature-store-offline-prefix', str(feature_store_offline_prefix),\n",
    "                         '--feature-group-name', str(feature_group_name)                         \n",
    "              ],\n",
    "              logs=True,\n",
    "              wait=False)\n",
    "\n",
    "else:\n",
    "    print('#######################################')\n",
    "    print('Please update the code correctly above.')\n",
    "    print('#######################################')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the information about the processing jobs using the `describe` function. The result is in dictionary format. Let's pull the processing job name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job name: sagemaker-scikit-learn-2021-07-28-00-58-27-975\n"
     ]
    }
   ],
   "source": [
    "scikit_processing_job_name = processor.jobs[-1].describe()['ProcessingJobName']\n",
    "\n",
    "print('Processing job name: {}'.format(scikit_processing_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-3'></a>\n",
    "### Exercise 3\n",
    "\n",
    "Pull the processing job status from the processing job description.\n",
    "\n",
    "**Instructions**: Print the keys of the processing job description dictionary, choose the one related to the status of the processing job and print the value of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ProcessingInputs', 'ProcessingOutputConfig', 'ProcessingJobName', 'ProcessingResources', 'StoppingCondition', 'AppSpecification', 'Environment', 'RoleArn', 'ProcessingJobArn', 'ProcessingJobStatus', 'LastModifiedTime', 'CreationTime', 'ResponseMetadata'])\n"
     ]
    }
   ],
   "source": [
    "print(processor.jobs[-1].describe().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job status: InProgress\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "scikit_processing_job_status = processor.jobs[-1].describe()[\"ProcessingJobStatus\"] # Replace None\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "print('Processing job status: {}'.format(scikit_processing_job_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the created processing job in the AWS console.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- notice that you are in the section `Amazon SageMaker` -> `Processing jobs`\n",
    "- check the name of the processing job, its status and other available information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs/sagemaker-scikit-learn-2021-07-28-00-58-27-975\">processing job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\">processing job</a></b>'.format(region, scikit_processing_job_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for about 5 minutes to review the CloudWatch Logs. You may open the file [src/prepare_data.py](src/prepare_data.py) again and examine the outputs of the code in the CloudWatch logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/ProcessingJobs;prefix=sagemaker-scikit-learn-2021-07-28-00-58-27-975;streamFilter=typeLogStreamPrefix\">CloudWatch logs</a> after about 5 minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch logs</a> after about 5 minutes</b>'.format(region, scikit_processing_job_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the completion of the processing job you can also review the output in the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/?region=us-east-1&tab=overview\">S3 output data</a> after the processing job has completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 output data</a> after the processing job has completed</b>'.format(bucket, scikit_processing_job_name, region)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the processing job to complete.\n",
    "\n",
    "### _This cell will take approximately 15 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................!CPU times: user 393 ms, sys: 58.5 ms, total: 452 ms\n",
      "Wall time: 7min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n",
    "    processing_job_name=scikit_processing_job_name,\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "running_processor.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Please wait until ^^ Processing Job ^^ completes above_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the transformed and balanced data in the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-train\n",
      "s3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-validation\n",
      "s3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-test\n"
     ]
    }
   ],
   "source": [
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "output_config = processing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'sentiment-train':\n",
    "        processed_train_data_s3_uri = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'sentiment-validation':\n",
    "        processed_validation_data_s3_uri = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'sentiment-test':\n",
    "        processed_test_data_s3_uri = output['S3Output']['S3Uri']\n",
    "        \n",
    "print(processed_train_data_s3_uri)\n",
    "print(processed_validation_data_s3_uri)\n",
    "print(processed_test_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-28 01:12:22    4899347 part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_train_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-28 01:12:22     273881 part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_validation_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-28 01:12:23     272142 part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_test_data_s3_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the data into the folder `balanced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n",
      "download: s3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n",
      "download: s3://sagemaker-us-east-1-519752018097/sagemaker-scikit-learn-2021-07-28-00-58-27-975/output/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $processed_train_data_s3_uri/part-algo-1-womens_clothing_ecommerce_reviews.tsv ./balanced/sentiment-train/\n",
    "!aws s3 cp $processed_validation_data_s3_uri/part-algo-1-womens_clothing_ecommerce_reviews.tsv ./balanced/sentiment-validation/\n",
    "!aws s3 cp $processed_test_data_s3_uri/part-algo-1-womens_clothing_ecommerce_reviews.tsv ./balanced/sentiment-test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the training, validation and test data outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\tsentiment\tlabel_id\tinput_ids\treview_body\tdate\n",
      "18645\t0\t1\t[0, 100, 2638, 42, 3588, 734, 29510, 939, 15158, 24, 4, 5, 6929, 161, 3563, 10397, 2569, 8, 4477, 3269, 7, 3841, 734, 5488, 939, 222, 36, 39956, 15, 15651, 322, 122, 24, 18, 45, 5, 276, 3588, 4, 24, 18, 350, 765, 8, 45, 25, 3793, 8, 939, 619, 98, 203, 8225, 59, 24, 4, 939, 2813, 5, 6929, 74, 95, 20587, 7, 3841, 2382, 1437, 939, 74, 582, 5, 1823, 5623, 7, 202, 33, 5, 3588, 939, 2638, 4, 95, 761, 9, 26678, 4, 98, 24, 18, 41, 6344, 3588, 1437, 95, 28, 2460, 7, 3841, 2382, 24, 50, 810, 17652, 1580, 114, 47, 10397, 24, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tI loved this dress...until i washed it. the label says machine wash cold and lay flat to dry...which i did (washed on delicate). now it's not the same dress. it's too short and not as soft and i feel so much differently about it. i wish the label would just instruct to dry clean  i would pay the extra expense to still have the dress i loved. just kind of annoyed. so it's an awesome dress  just be prepared to dry clean it or risk shrinkage if you wash it.\t2021-07-28T01:06:21Z\n",
      "4487\t0\t1\t[0, 31231, 33, 2740, 5, 3023, 462, 1386, 9, 5, 739, 4, 399, 75, 190, 283, 593, 7, 145, 441, 7, 6148, 5, 760, 53, 939, 437, 10, 2631, 821, 4, 939, 465, 13488, 7, 422, 650, 4, 2721, 3793, 2272, 3195, 1437, 10199, 16, 3793, 350, 4, 24, 16, 30197, 7, 5, 13977, 4, 1276, 7, 671, 1386, 9, 769, 10337, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tShould have ordered the xl instead of the large. didn't even come close to being able to button the front but i'm a 34 g. i find sanctuary to run small. beautiful soft green color  fabric is soft too. it is cropped to the waist. decided to return instead of reorder.\t2021-07-28T01:06:21Z\n",
      "15169\t-1\t0\t[0, 100, 33, 10, 1763, 9, 475, 4001, 10844, 14, 32, 5, 129, 10844, 939, 308, 14, 939, 3668, 657, 4, 960, 59, 106, 4, 42, 16338, 1415, 16106, 1437, 5616, 8, 1531, 1437, 98, 939, 11743, 710, 4462, 148, 5, 564, 207, 160, 3588, 1392, 4, 1437, 127, 676, 19, 475, 4001, 16, 14, 5, 39328, 1237, 1528, 1437, 50, 2287, 2379, 260, 1437, 8, 4634, 650, 4, 939, 2740, 42, 11, 10, 4761, 8, 24, 16, 40696, 927, 7372, 25, 157, 25, 8077, 1481, 1115, 13802, 4, 24, 1415, 11385, 31, 358, 11792, 35, 760, 1437, 124, 8, 2380, 4, 939, 1395, 4744, 24, 519, 55, 2564, 190, 11, 10, 2735, 1836, 4, 1437, 5, 10199, 16, 2579, 1437, 181, 2, 1, 1, 1, 1, 1]\tI have a pair of mih jeans that are the only jeans i own that i absolutely love. everything about them. this jumper looked versatile  useful and fun  so i splurged during the 25% off dress sale.  my experience with mih is that the sizing runs true  or european  and thus small. i ordered this in a medium and it is gargantuan as well as virtually shapeless. it looked horrible from every angle: front  back and sides. i cannot imagine it having more fit even in a smaller size.  the fabric is nice  p\t2021-07-28T01:06:21Z\n",
      "9761\t1\t2\t[0, 100, 33, 129, 10610, 42, 155, 498, 19, 117, 2434, 9, 181, 7491, 1437, 648, 4, 24, 16, 205, 13, 3035, 2428, 360, 73, 12963, 1033, 4, 13, 162, 1437, 24, 581, 28, 5, 12924, 155, 12, 1090, 32781, 23204, 4, 939, 3568, 10, 1836, 739, 8, 24, 10698, 5083, 4, 939, 33, 10610, 13719, 251, 24150, 29716, 3055, 293, 223, 42, 19, 5136, 11, 5, 21764, 4, 939, 206, 10, 11875, 30145, 5202, 6399, 73, 3662, 11556, 74, 173, 6681, 157, 4, 150, 939, 101, 5, 1114, 9, 5, 12189, 1437, 939, 206, 51, 581, 4140, 66, 2773, 1684, 10, 11576, 50, 2119, 865, 8232, 4, 939, 2928, 112, 999, 528, 7, 5, 239, 425, 8, 939, 1325, 2, 1, 1, 1, 1, 1, 1, 1]\tI have only worn this 3 times with no signs of pilling  yet. it is good for cool spring days/evenings. for me  it'll be the cooler 3-seasons sweater. i wear a size large and it fits properly. i have worn lightweight long sleeve knit tees under this with ease in the sleeves. i think a slim sleeved shirt/blouse would work equally well. while i like the idea of the pockets  i think they'll stretch out easily beyond a tissue or quick hand warming. i removed 1 star due to the high price and i receive\t2021-07-28T01:06:21Z\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./balanced/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\tsentiment\tlabel_id\tinput_ids\treview_body\tdate\n",
      "7996\t1\t2\t[0, 16587, 657, 5, 5780, 15, 209, 53, 5, 2564, 16, 160, 4, 939, 1381, 15, 5, 2705, 3195, 11, 42, 276, 2496, 8, 939, 362, 127, 1675, 1836, 389, 4, 209, 939, 956, 10, 316, 4, 5, 13977, 1302, 269, 650, 53, 5, 2576, 2985, 1667, 4140, 66, 8, 32, 761, 9, 3298, 4740, 71, 112, 3568, 4, 939, 64, 75, 213, 159, 10, 1836, 142, 5, 13977, 21, 350, 650, 15, 5, 158, 4, 187, 939, 657, 5, 5780, 98, 203, 24, 189, 28, 30795, 868, 4, 3159, 13, 37, 118, 37, 118, 7, 2564, 351, 4122, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tLove love the print on these but the fit is off. i tried on the solid color in this same style and i took my regular size 30. these i needed a 12. the waist seems really small but the bottom leg parts stretch out and are kind of baggy after 1 wear. i can't go down a size because the waist was too small on the 10. since i love the print so much it may be tolerable. rare for hei hei to fit wonky.\t2021-07-28T01:06:21Z\n",
      "7826\t1\t2\t[0, 713, 16, 10, 465, 328, 939, 524, 460, 15, 5, 8131, 13, 10, 5425, 784, 35470, 98, 77, 939, 303, 42, 15, 10, 22, 19256, 8, 4786, 20004, 113, 939, 439, 13, 24, 4, 13, 9770, 1437, 939, 524, 195, 2767, 818, 231, 4877, 1437, 8, 24, 5, 5933, 3587, 95, 59, 5, 276, 317, 15, 42, 1421, 4, 939, 2333, 3568, 10, 1836, 132, 53, 77, 939, 1381, 15, 5, 1836, 577, 11, 5, 1400, 36, 3036, 43, 1437, 939, 1299, 939, 129, 956, 10, 828, 723, 39328, 42790, 939, 524, 650, 11, 5, 7050, 4, 939, 524, 6254, 10, 1836, 2631, 10, 8, 1153, 10, 389, 417, 23, 275, 1437, 8, 939, 6254, 64, 15020, 127, 7050, 88, 42, 3588, 23, 42, 1836, 328, 2]\t\"This is a find! i am always on the hunt for a unusual lbd so when i found this on a \"\"found and collected rack\"\" i went for it. for starters  i am 5 foot almost 6 inches  and it the length ends just about the same place on this model. i usually wear a size 2 but when i tried on the size available in the store (oo)  i felt i only needed a bit higher sizing bc i am small in the chest. i am barely a size 34 a and probably a 30d at best  and i barely can squeeze my chest into this dress at this size!\"\t2021-07-28T01:06:21Z\n",
      "16102\t0\t1\t[0, 100, 437, 195, 108, 401, 113, 1437, 2631, 428, 73, 2881, 438, 1437, 1553, 45766, 10529, 10431, 1437, 359, 5258, 23341, 98, 939, 33, 2671, 73, 13792, 32188, 784, 2923, 1437, 124, 1437, 3701, 4, 127, 795, 457, 939, 3568, 579, 329, 564, 985, 1437, 5951, 1437, 50, 262, 30515, 10844, 1437, 53, 2853, 16, 55, 5679, 36, 306, 12, 401, 579, 329, 322, 28097, 1553, 45766, 1718, 113, 1437, 13977, 971, 845, 127, 13657, 35, 939, 218, 75, 101, 383, 3229, 4, 939, 2740, 4761, 1437, 299, 10698, 1969, 1437, 53, 13977, 73, 7903, 939, 33, 185, 11, 25, 55, 101, 10, 24577, 73, 620, 4822, 1437, 1751, 2855, 31365, 13178, 219, 1907, 10199, 1437, 45, 2422, 1109, 1855, 4822, 261, 25, 2356, 2082, 4, 2]\t\"I'm 5'6\"\"  34b/32c  apprx 125#  & lift weights so i have bigger/muscular lats  back  arms. my lower half i wear sz 25 mother  ag  or 7 mankind jeans  but upper is more med (4-6 sz). hips apprx 35\"\"  waist 28\"\". my tops: i don't like things tight. i ordered medium  top fits perfect  but waist/hips i have take in as more like a rigid/stiff  gunny sax cottony type fabric  not super light chiffon as photos appear. the under lining super short in front and top of calf in back  but lining follows the she\"\t2021-07-28T01:06:21Z\n",
      "323\t1\t2\t[0, 100, 2162, 5, 3588, 14, 34, 5, 6353, 16576, 19, 739, 7716, 4, 939, 5328, 24, 13, 10, 3312, 8, 21, 45, 129, 182, 3473, 19, 5, 12189, 8, 5, 13178, 299, 1437, 939, 1415, 205, 4, 939, 300, 10, 319, 9, 33391, 15, 5, 7490, 4, 82, 802, 24, 21, 10, 6399, 8, 3089, 11556, 1195, 87, 10, 3588, 4, 939, 2638, 5, 239, 614, 16576, 4, 5, 39328, 21, 6030, 8, 5, 3588, 16, 1365, 7, 2382, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tI bought the dress that has the cream skirt with large flowers. i wore it for a wedding and was not only very comfortable with the pockets and the cotton top  i looked good. i got a lot of compliments on the outfit. people thought it was a shirt and blouse rather than a dress. i loved the high low skirt. the sizing was accurate and the dress is easy to clean.\t2021-07-28T01:06:21Z\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./balanced/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\tsentiment\tlabel_id\tinput_ids\treview_body\tdate\n",
      "1346\t-1\t0\t[0, 100, 2638, 42, 23204, 77, 939, 794, 24, 804, 8, 2740, 235, 409, 4, 939, 3584, 10, 579, 8, 5, 2564, 21, 182, 160, 4, 5, 3701, 58, 251, 36, 5488, 939, 218, 75, 1508, 43, 53, 5, 23204, 21, 67, 2422, 2016, 8, 35156, 98, 24, 21, 45, 23, 70, 34203, 4, 939, 269, 770, 7, 657, 24, 8, 24, 2551, 7, 28, 9, 205, 1318, 53, 24, 939, 56, 7, 671, 24, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tI loved this sweater when i saw it online and ordered right away. i purchased a s and the fit was very off. the arms were long (which i don't mind) but the sweater was also super heavy and bulky so it was not at all flattering. i really wanted to love it and it seemed to be of good quality but it i had to return it.\t2021-07-28T01:06:21Z\n",
      "10092\t-1\t0\t[0, 100, 21, 98, 2283, 7, 1325, 42, 3588, 129, 7, 283, 465, 66, 14, 24, 21, 45, 11901, 10247, 1437, 45, 5, 276, 8089, 25, 5, 2170, 1437, 2292, 463, 3463, 1468, 1437, 5, 2564, 1237, 2735, 87, 144, 9, 49, 14442, 8, 5, 21764, 32, 10835, 4, 939, 657, 6215, 8, 6573, 49, 5418, 1065, 70, 97, 3595, 53, 939, 21, 2778, 5779, 11, 42, 3588, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tI was so excited to receive this dress only to come find out that it was not tweed  not the same colors as the picture  spandex material  the fit runs smaller than most of their dresses and the sleeves are capped. i love retailer and prefer their clothes above all other brands but i was extremely disappointed in this dress.\t2021-07-28T01:06:21Z\n",
      "8484\t0\t1\t[0, 713, 299, 16, 203, 13116, 254, 1437, 55, 1928, 12, 417, 3937, 8, 2233, 906, 87, 7092, 4, 14187, 16, 13116, 350, 1437, 8, 8089, 55, 27891, 87, 2343, 4, 939, 3568, 741, 24019, 13657, 70, 5, 86, 8, 42, 1415, 6587, 15, 162, 36, 118, 33, 4007, 12, 1173, 10762, 8, 10, 7050, 322, 939, 802, 24, 74, 28, 10, 1531, 1437, 385, 31766, 219, 299, 13, 3868, 7, 1136, 53, 9574, 24, 18, 164, 124, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tThis top is much stiffer  more baby-doll and boxier than pictured. lining is stiff too  and colors more muddy than shown. i wear boho tops all the time and this looked terrible on me (i have broad-ish shoulders and a chest). i thought it would be a fun  drapey top for transition to fall but unfortunately it's going back.\t2021-07-28T01:06:21Z\n",
      "7635\t1\t2\t[0, 713, 21, 10, 94, 2289, 1285, 7, 127, 804, 645, 7, 478, 5, 481, 6738, 328, 6992, 734, 42, 1249, 62, 145, 127, 2674, 6880, 31, 127, 645, 328, 939, 657, 5, 169, 24, 18166, 8, 67, 22533, 490, 4, 939, 399, 75, 4883, 14, 5, 10199, 21, 10, 3344, 9, 80, 430, 11269, 2629, 1437, 53, 939, 206, 24, 3639, 2579, 773, 4, 939, 2740, 5, 1275, 61, 16, 10, 2579, 1437, 1844, 1275, 734, 3654, 41, 39701, 668, 3819, 1275, 4, 24, 18, 182, 22310, 7, 127, 3024, 6328, 8, 2933, 2549, 4, 939, 422, 227, 10, 650, 8, 4761, 1437, 53, 4689, 5, 4761, 187, 24, 1415, 101, 24, 740, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tThis was a last minute addition to my online order to hit the free shipping! anyway... this ended up being my favorite item from my order! i love the way it wraps and also lays open. i didn't realize that the fabric was a mix of two different knits  but i think it adds nice interest. i ordered the red which is a nice  deep red...not an obnoxious fire engine red. it's very complimentary to my skin tone and dark hair. i run between a small and medium  but chose the medium since it looked like it c\t2021-07-28T01:06:21Z\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./balanced/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-3.'></a>\n",
    "# 3. Query the Feature Store\n",
    "In addition to transforming the data and saving in S3 bucket, the processing job populates the feature store with the transformed and balanced data.  Let's query this data using Amazon Athena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-3.1.'></a>\n",
    "### 3.1. Export training, validation, and test datasets from the Feature Store\n",
    "\n",
    "Here you will do the export only for the training dataset, as an example. \n",
    "\n",
    "Use `athena_query()` function to create an Athena query for the defined above Feature Group. Then you can pull the table name of the Amazon Glue Data Catalog table which is auto-generated by Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glue Catalog table name: reviews-feature-group-1627433581-1627434336\n",
      "Running query: \n",
      "    SELECT date,\n",
      "        review_id,\n",
      "        sentiment, \n",
      "        label_id,\n",
      "        input_ids,\n",
      "        review_body\n",
      "    FROM \"reviews-feature-group-1627433581-1627434336\" \n",
      "    WHERE split_type='train' \n",
      "    LIMIT 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_store_query = feature_group.athena_query()\n",
    "\n",
    "feature_store_table = feature_store_query.table_name\n",
    "\n",
    "query_string = \"\"\"\n",
    "    SELECT date,\n",
    "        review_id,\n",
    "        sentiment, \n",
    "        label_id,\n",
    "        input_ids,\n",
    "        review_body\n",
    "    FROM \"{}\" \n",
    "    WHERE split_type='train' \n",
    "    LIMIT 5\n",
    "\"\"\".format(feature_store_table)\n",
    "\n",
    "print('Glue Catalog table name: {}'.format(feature_store_table))\n",
    "print('Running query: {}'.format(query_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the S3 location for the query results.  This allows us to re-use the query results for future queries if the data has not changed.  We can even share this S3 location between team members to improve query performance for common queries on data that does not change often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-519752018097/query_results/reviews-feature-store-1627433581/\n"
     ]
    }
   ],
   "source": [
    "output_s3_uri = 's3://{}/query_results/{}/'.format(bucket, feature_store_offline_prefix)\n",
    "print(output_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-4'></a>\n",
    "### Exercise 4\n",
    "\n",
    "Query the feature store.\n",
    "\n",
    "**Instructions**: Use `feature_store_query.run` function passing the constructed above query string and the location of the output S3 bucket.\n",
    "\n",
    "```python\n",
    "feature_store_query.run(\n",
    "    query_string=..., # query string\n",
    "    output_location=... # location of the output S3 bucket\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_query.run(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    query_string=query_string, # Replace None\n",
    "    output_location=output_s3_uri # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")\n",
    "\n",
    "feature_store_query.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-28T01:06:21Z</td>\n",
       "      <td>12444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 100, 2162, 10, 3235, 1122, 7, 42, 94, 76, 1437, 8, 2638, 24, 328, 42, 76, 939, 2162, 5, 3333...</td>\n",
       "      <td>I bought a suit similar to this last year  and loved it! this year i bought the pineapple print ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-28T01:06:21Z</td>\n",
       "      <td>18990</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 713, 3588, 23835, 35907, 4, 7328, 5, 1345, 1437, 5, 13977, 473, 45, 740, 3796, 4, 350, 1099,...</td>\n",
       "      <td>This dress hangs horribly. unlike the photo  the waist does not cinch. too bad. the colors are g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-28T01:06:21Z</td>\n",
       "      <td>6891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 10365, 44184, 131, 1109, 8, 3473, 1468, 53, 5, 3318, 12, 20020, 782, 10, 6399, 19, 10, 828, ...</td>\n",
       "      <td>Too floppy; light and comfortable material but the tie-neck needs a shirt with a bit more struct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-28T01:06:21Z</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 100, 348, 57, 546, 23, 209, 13, 103, 86, 8, 939, 1747, 2468, 5, 7691, 4, 939, 437, 7785, 939...</td>\n",
       "      <td>I've been looking at these for some time and i finally pulled the trigger. i'm glad i did becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-28T01:06:21Z</td>\n",
       "      <td>7056</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 100, 1064, 11, 657, 19, 209, 17539, 6806, 23, 78, 1082, 4, 939, 21, 10, 410, 3915, 51, 74, 4...</td>\n",
       "      <td>I fell in love with these bottoms at first site. i was a little worried they would not work for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  review_id  sentiment  label_id  \\\n",
       "0  2021-07-28T01:06:21Z      12444          1         2   \n",
       "1  2021-07-28T01:06:21Z      18990         -1         0   \n",
       "2  2021-07-28T01:06:21Z       6891          0         1   \n",
       "3  2021-07-28T01:06:21Z       1389          1         2   \n",
       "4  2021-07-28T01:06:21Z       7056          1         2   \n",
       "\n",
       "                                                                                             input_ids  \\\n",
       "0  [0, 100, 2162, 10, 3235, 1122, 7, 42, 94, 76, 1437, 8, 2638, 24, 328, 42, 76, 939, 2162, 5, 3333...   \n",
       "1  [0, 713, 3588, 23835, 35907, 4, 7328, 5, 1345, 1437, 5, 13977, 473, 45, 740, 3796, 4, 350, 1099,...   \n",
       "2  [0, 10365, 44184, 131, 1109, 8, 3473, 1468, 53, 5, 3318, 12, 20020, 782, 10, 6399, 19, 10, 828, ...   \n",
       "3  [0, 100, 348, 57, 546, 23, 209, 13, 103, 86, 8, 939, 1747, 2468, 5, 7691, 4, 939, 437, 7785, 939...   \n",
       "4  [0, 100, 1064, 11, 657, 19, 209, 17539, 6806, 23, 78, 1082, 4, 939, 21, 10, 410, 3915, 51, 74, 4...   \n",
       "\n",
       "                                                                                           review_body  \n",
       "0  I bought a suit similar to this last year  and loved it! this year i bought the pineapple print ...  \n",
       "1  This dress hangs horribly. unlike the photo  the waist does not cinch. too bad. the colors are g...  \n",
       "2  Too floppy; light and comfortable material but the tie-neck needs a shirt with a bit more struct...  \n",
       "3  I've been looking at these for some time and i finally pulled the trigger. i'm glad i did becaus...  \n",
       "4  I fell in love with these bottoms at first site. i was a little worried they would not work for ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "\n",
    "df_feature_store = feature_store_query.as_dataframe()\n",
    "df_feature_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the Feature Store in SageMaker Studio\n",
    "\n",
    "![](images/sm_studio_extensions_featurestore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-3.2.'></a>\n",
    "### 3.2. Export TSV from Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output as a TSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_store.to_csv('./feature_store_export.tsv',\n",
    "                        sep='\\t',\n",
    "                        index=False,\n",
    "                        header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\treview_id\tsentiment\tlabel_id\tinput_ids\treview_body\n",
      "2021-07-28T01:06:21Z\t12444\t1\t2\t[0, 100, 2162, 10, 3235, 1122, 7, 42, 94, 76, 1437, 8, 2638, 24, 328, 42, 76, 939, 2162, 5, 33336, 5780, 1437, 8, 24, 16, 2721, 36, 10799, 132, 322, 24, 16, 30228, 73, 1090, 32027, 4, 939, 33, 10, 251, 28762, 1437, 98, 939, 101, 14, 24, 4865, 162, 357, 87, 144, 65, 2125, 6966, 10401, 939, 860, 15, 4, 939, 2200, 5940, 42, 1152, 328, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tI bought a suit similar to this last year  and loved it! this year i bought the pineapple print  and it is beautiful (size 2). it is classy/sexy. i have a long torso  so i like that it covers me better than most one piece swim suits i try on. i highly recommend this product!\n",
      "2021-07-28T01:06:21Z\t18990\t-1\t0\t[0, 713, 3588, 23835, 35907, 4, 7328, 5, 1345, 1437, 5, 13977, 473, 45, 740, 3796, 4, 350, 1099, 4, 5, 8089, 32, 372, 8, 5, 1318, 9, 5, 1468, 16, 2579, 4, 142, 939, 2162, 24, 15, 1392, 1437, 939, 189, 860, 7, 26090, 24, 7, 173, 1437, 53, 3867, 47, 32, 2882, 7, 109, 14, 1437, 63, 10, 117, 213, 4, 4832, 38203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tThis dress hangs horribly. unlike the photo  the waist does not cinch. too bad. the colors are great and the quality of the material is nice. because i bought it on sale  i may try to tailor it to work  but unless you are willing to do that  its a no go. :-(\n",
      "2021-07-28T01:06:21Z\t6891\t0\t1\t[0, 10365, 44184, 131, 1109, 8, 3473, 1468, 53, 5, 3318, 12, 20020, 782, 10, 6399, 19, 10, 828, 55, 3184, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tToo floppy; light and comfortable material but the tie-neck needs a shirt with a bit more structure.\n",
      "2021-07-28T01:06:21Z\t1389\t1\t2\t[0, 100, 348, 57, 546, 23, 209, 13, 103, 86, 8, 939, 1747, 2468, 5, 7691, 4, 939, 437, 7785, 939, 222, 142, 209, 326, 6183, 32, 215, 10, 1531, 21883, 7, 1606, 7, 127, 18704, 4, 51, 1606, 95, 615, 31754, 8628, 7, 4187, 14442, 8, 31296, 4, 209, 32, 45, 110, 7476, 7174, 4140, 219, 326, 6183, 4, 51, 8736, 162, 9, 5, 326, 6183, 939, 74, 3568, 11, 5, 2608, 25, 10, 410, 1816, 131, 51, 32, 269, 23204, 326, 6183, 4, 939, 206, 42, 6659, 16, 372, 1437, 53, 51, 109, 45, 33, 25, 203, 492, 25, 97, 326, 6183, 4, 939, 524, 4716, 1459, 1437, 59, 195, 108, 246, 113, 12730, 23246, 8, 5, 650, 2, 1, 1, 1, 1, 1, 1, 1]\t\"I've been looking at these for some time and i finally pulled the trigger. i'm glad i did because these tights are such a fun accessory to add to my wardrobe. they add just enough whimsy to classic dresses and skirts. these are not your everyday thin stretchy tights. they remind me of the tights i would wear in the winter as a little girl; they are really sweater tights. i think this aspect is great  but they do not have as much give as other tights. i am petite  about 5'3\"\" 112 lbs and the small\"\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./feature_store_export.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload TSV to the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./feature_store_export.tsv to s3://sagemaker-us-east-1-519752018097/feature_store/feature_store_export.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./feature_store_export.tsv s3://$bucket/feature_store/feature_store_export.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the file in the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-28 01:14:36       4425 feature_store/feature_store_export.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive s3://$bucket/feature_store/feature_store_export.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-3.3.'></a>\n",
    "### 3.3. Check that the dataset in the Feature Store is balanced by sentiment\n",
    "\n",
    "Now you can setup an Athena query to check that the stored dataset is balanced by the target class `sentiment`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-5'></a>\n",
    "### Exercise 5\n",
    "\n",
    "Write an SQL query to count the total number of the reviews per `sentiment` stored in the Feature Group.\n",
    "\n",
    "**Instructions**: Pass the SQL statement of the form \n",
    "\n",
    "```sql\n",
    "SELECT category_column, COUNT(*) AS new_column_name\n",
    "FROM table_name\n",
    "GROUP BY category_column\n",
    "```\n",
    "\n",
    "into the variable `query_string_count_by_sentiment`. Here you would need to use the column `sentiment` and give a name `count_reviews` to the new column with the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_query_2 = feature_group.athena_query()\n",
    "\n",
    "# Replace all None\n",
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "query_string_count_by_sentiment = \"\"\"\n",
    "SELECT sentiment, COUNT(*) AS count_reviews\n",
    "FROM \"{}\"\n",
    "GROUP BY sentiment\n",
    "\"\"\".format(feature_store_table)\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-6'></a>\n",
    "### Exercise 6\n",
    "\n",
    "Query the feature store.\n",
    "\n",
    "**Instructions**: Use `run` function of the Feature Store query, passing the new query string `query_string_count_by_sentiment`. The output S3 bucket will remain unchanged. You can follow the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  count_reviews\n",
       "0          1           2051\n",
       "1          0           2051\n",
       "2         -1           2051"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_store_query_2.run(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    query_string=query_string_count_by_sentiment, # Replace None\n",
    "    output_location=output_s3_uri # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")\n",
    "\n",
    "feature_store_query_2.wait()\n",
    "\n",
    "df_count_by_sentiment = feature_store_query_2.as_dataframe()\n",
    "df_count_by_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w1-ex-7'></a>\n",
    "### Exercise 7\n",
    "\n",
    "Visualize the result of the query in the bar plot, showing the count of the reviews by sentiment value.\n",
    "\n",
    "**Instructions**: Pass the resulting data frame `df_count_by_sentiment` into the `barplot` function of the `seaborn` library.\n",
    "\n",
    "```python\n",
    "sns.barplot(\n",
    "    data=..., \n",
    "    x='...', \n",
    "    y='...',\n",
    "    color=\"blue\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f71d6ba4850>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    data=df_count_by_sentiment, # Replace None\n",
    "    x=\"sentiment\", # Replace None\n",
    "    y=\"count_reviews\", # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    color=\"blue\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook and `prepare_data.py` file into S3 bucket for grading purposes.\n",
    "\n",
    "**Note**: you may need to save the file before the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./C2_W1_Assignment.ipynb to s3://sagemaker-us-east-1-519752018097/C2_W1_Assignment_Learner.ipynb\n",
      "upload: src/prepare_data.py to s3://sagemaker-us-east-1-519752018097/src/C2_W1_prepare_data_Learner.py\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./C2_W1_Assignment.ipynb s3://$bucket/C2_W1_Assignment_Learner.ipynb\n",
    "!aws s3 cp ./src/prepare_data.py s3://$bucket/src/C2_W1_prepare_data_Learner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go to the main lab window and click on `Submit` button (see the `Finish the lab` section of the instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
